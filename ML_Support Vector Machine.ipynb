{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31de69d6",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7443abb",
   "metadata": {
    "id": "primary-soundtrack",
    "outputId": "975564e6-ffc9-45ee-ce5b-0e2191db8194"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(\"Financial_Mexican_Firms.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65575f42",
   "metadata": {},
   "source": [
    "- Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212621a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = df.iloc[:, 0:10]\n",
    "y  = df.iloc[:, 10]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0) \n",
    "df_train = pd.concat([X_train, y_train], axis = 1)\n",
    "df_test  = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae21899",
   "metadata": {},
   "source": [
    "- Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2b0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Imputation techniques\n",
    "iregression_imputer = IterativeImputer(estimator = LinearRegression(), \n",
    "                                   missing_values = np.nan, \n",
    "                                   max_iter = 5, \n",
    "                                   imputation_order = 'roman', \n",
    "                                   random_state = 0)\n",
    "\n",
    "# Apply an Imputation technique for training & testing datasets and rename columns\n",
    "df_train  = pd.DataFrame(iregression_imputer.fit_transform(df_train), columns = ['ProposedIndex', \n",
    "                                                                 'IIHH',  \n",
    "                                                                 'Shannon',\n",
    "                                                                 'Size',\n",
    "                                                                 'AssetTurnover',\n",
    "                                                                 'Debt',\n",
    "                                                                 'QuickRatio',\n",
    "                                                                 'CashHoldings',\n",
    "                                                                 'ROE',\n",
    "                                                                 'ROI',\n",
    "                                                                 'ROA'])\n",
    "\n",
    "df_test  = pd.DataFrame(iregression_imputer.fit_transform(df_test), columns = ['ProposedIndex', \n",
    "                                                                 'IIHH',  \n",
    "                                                                 'Shannon',\n",
    "                                                                 'Size',\n",
    "                                                                 'AssetTurnover',\n",
    "                                                                 'Debt',\n",
    "                                                                 'QuickRatio',\n",
    "                                                                 'CashHoldings',\n",
    "                                                                 'ROE',\n",
    "                                                                 'ROI', \n",
    "                                                                 'ROA'])\n",
    "\n",
    "# Update the training set\n",
    "X_train  = df_train.iloc[:,:-1]\n",
    "y_train  = df_train.ROA\n",
    "\n",
    "X_test  = df_test.iloc[:,:-1]\n",
    "y_test  = df_test.ROA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fd297",
   "metadata": {},
   "source": [
    "- Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3798c4d",
   "metadata": {
    "id": "sensitive-support"
   },
   "outputs": [],
   "source": [
    "# Specify different values for the tunning process\n",
    "kfold  = KFold(n_splits = 5, random_state = None, shuffle = False)\n",
    "\n",
    "kernel  = ['rbf', 'poly', 'sigmoid']\n",
    "degree  = [1, 2, 3, 4]\n",
    "gamma   = ['scale', 'auto']\n",
    "C       = [0.01, 0.1, 1, 5]\n",
    "epsilon = [0.1, 0.25, 0.75]\n",
    "\n",
    "#Create parameter grid\n",
    "myparamgrid = [{'kernel' : kernel,\n",
    "                'degree' : degree, \n",
    "                'C'      : C,\n",
    "                'epsilon': epsilon}]\n",
    "\n",
    "#Create SVR object\n",
    "model  = SVR()\n",
    "\n",
    "#Grid Search CV\n",
    "svmsearch   = GridSearchCV(model, \n",
    "                           myparamgrid, \n",
    "                           scoring= 'r2', \n",
    "                           cv = kfold, \n",
    "                           verbose= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3b9ee",
   "metadata": {},
   "source": [
    "- Fit the model and measure time to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c33620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 0 minutes and 1.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "        \n",
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "svmsearch.fit(X_train,y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e432268",
   "metadata": {},
   "source": [
    "- Get the best tunning parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a1df0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'degree': 4, 'epsilon': 0.1, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmsearch.best_estimator_\n",
    "svmsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66eba49",
   "metadata": {},
   "source": [
    "- Specify the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d07d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = SVR(kernel     = 'poly', \n",
    "                    degree     = 4, \n",
    "                    C          = 5, \n",
    "                    epsilon    = 0.1, \n",
    "                    cache_size = 5000).fit(X_train, y_train)                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb5b00",
   "metadata": {},
   "source": [
    "- Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682eae3f",
   "metadata": {
    "id": "whole-terrace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2  : 0.3667561776278284\n",
      "MAE : 0.03552341662914489\n",
      "MSE : 0.0027332904978663642\n",
      "RMSE: 0.05228088080614522\n",
      "Processing time: 0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "y_pred     = optimal_model.predict(X_test)\n",
    "    \n",
    "print('R2  :', r2_score(y_test, y_pred))\n",
    "print('MAE :', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE :', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('Processing time: %s seconds' % round((time.time() - start_time), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567f656",
   "metadata": {},
   "source": [
    "- Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9897da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(\"SVR_Diversification.pkl\", 'wb')\n",
    "pickle.dump(optimal_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44aade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
